\section{Ausiello Algorithm: Implementation}

\subsection{Data Structure}

\subsubsection{Recall the theoretical structure}

In this paragraph, we will recall essential elements of an FD-Graphs, namely
the possible arcs, the structure we may need to compute closure and so forth.

\subsubsection{Code definition}

The algorithms are given in terms of the size of an FD-graph. In 
\cite{ausiello_minimal_1986}, one can read that this size is assumed to be the
size of a graph under adjacency list representation. Using a matrix based 
structure would take a quadratic amount of memory, and would be less efficient
for adding/removing nodes, unmatching theoretical complexity. In the next
paragraphs, we will explain more precisely the structure we chosen.

\vspace{1.2em}

An FD-Graph can have two types of nodes (simple, compound), and up to 5 type
of arcs (full, dotted, closed full, closed dotted, D). Furthermore, for closure
and marking purposes, each vertex must have a counter embedded. Finally, we
are supposed to build a graph out of an implication system based on 
\lil{BitSet}. Hence, to ease conversion and computations, we label each vertex
by its \lil{BitSet} representation. Eventually, a vertex will be defined as in 
the following snippet:

\begin{lstlisting}[language=CoreCpp, style=Light, breaklines=true]
typedef struct vertex vertex_t;

struct vertex{
  std::map<std::string, std::list<elt_t *>> edges;
  unsigned int counter;
};

typedef std::pair<FCA::BitSet, vertex_t> elt_t;

\end{lstlisting}

\noindent Where \lil{elt_t} will be elements stored in the overhaul graph 
structure, being only a list of \lil{elt_t}:

\begin{lstlisting}[language=CoreCpp, style=Light, breaklines=true]
typedef std::list<elt_t> graph;
\end{lstlisting}

\noindent Note that we use pointer on adjacent nodes to represent edges 
(\lil{std::list<elt_t *>}). This avoids duplication of \lil{BitSet}, ease use 
of counters and allow for fast access to one node to a given adjacent one. The 
\lil{map} structure deserves to represent all type of edges a vertex can have.
We prefered \lil{map} instead of say \lil{list} or \lil{vector} for the 
trade-off between access and code readability. Having string keys makes the code
clearer, while keeping a logarithmic access time to a given list. Because the 
number of list is constant, the excess of computations with respect to a 
\lil{vector} is negligible. 

\vspace{1.2em}

In order to illustrate, we give an example of a simple basis $ab \imp c$ 
represented through FD-Graph both graphically and with our data structure in
figure \ref{fig:Graph-DS}. In this figure "\&" stands for the \belemp{address}
of following vertex. Also, for sake of clarity we did not drawn the closure of 
the graph nor the counters. Only initial arcs are represented: dotted, full and 
D ones. 
 

\begin{figure}[ht]
	\input{Pictures/Graph-DS.tex}
	\label{fig:Graph-DS}
\end{figure}

Due to lack of time, this is the only structure we provided. Here are
some ideas and points that one should read in regard to implement another 
structure for representing FD-Graphs. First recall that the graph should have
a space complexity in $O(|\I|)$ according to Ausiello and al. (see 
\cite{ausiello_minimal_1986}). In this paper, implication basis are provided
under hypergraphs framework and the size $|\I|$ of $\I$ is the size of the 
structure in terms of adjacency lists. Fortunately, whether we consider 
hypergraphs or usual set notations, $|I|$ is still $O(|B||\Sg|)$ since we 
have $|B|$ hyperarcs, going to at most $|\Sg|$ single attributes (under reduced
form). The size of the associated FD-Graph should be linear in the size $\I$.

\vspace{1.2em}

We are going to investigate our structure. Because we made a structure supposed
to store the closure of a graph also, we will study here the space used only
for representation of the FD-Graph (simple/compound nodes, and dotted/full 
arcs) to be fair in comparison:
\begin{itemize}
	\item we have $O(|\Sg| + |B|)$ nodes,
	\item we will have full arcs to single attributes for bodies only, 
	that is, $O(|B||\Sg|)$ = $O(|\I|)$ space complexity,
	\item we will have dotted arcs only from compound bodies of $\I$ to 
	single attributes, also resulting in $O(|\I|)$ space complexity,
	\item for each dotted arc, we will have a D-arc, leading also to $O(|\I|)$
	space complexity
\end{itemize}
Summing up, we will have at most $O(|\Sg| + |B|)$ vertices and $O(3|\I|)$ 
edges into the whole graph, resulting in $O(|\Sg| + |B| + 3|\I|) = O(|\I|)$ 
space complexity. 

\vspace{1.2em}

Note that the closure has a space complexity of $O((|B| + |\Sg|)^2) = O(|\I|^2)$
because the closure can be a complete graph. This also matches theoretic 
expectations. Because algorithms sometimes need to run over compound nodes 
only, single attributes only or bodies only, we could have split the lists 
of vertices into both single and compound nodes. Here are few arguments 
explaining why we did not make so:
\begin{itemize}
	\item single attribute can be bodies of $\I$, meaning that tearing apart
	single attributes on the one hand, and compound ones on the other would 
	have bodies of $\I$ (nodes with full arcs) distributed over two 
	distinct structures, breaking the interest of splitting;
	
	\item whereas the split would have ease for loops in algorithms, limiting
	them to a minimal number of steps, because structure may implicitly refers
	to each other (through edges), we would have lost code readability;
	
	\item the gain obtained in previously mentioned loops is also negligible
	in a sense. Provided we run over all vertices  of the graph, selecting a
	vertex or not according to its properties is $O(1)$. Consequently, 
	computations for vertices not matching wanted properties are reduced to this
	$O(1)$ checking, giving a small practical computation overhead and same 
	theoretical complexity as divided nodes structure.
\end{itemize}
\noindent Also, to keep this splitting, we could have duplicated some nodes in
order not to jump implicitly from one structure to another. But this would have
obsoletely increased allocated space, and may have caused problem or required 
more operations for proper removal of vertices and edges. Indeed, we would have
been compelled to check that if a node is deleted, there is no duplicate left
in other lists. 

\subsubsection{A quick overview of complexity}

In this part, we will describe a complexity analysis of routines not being 
algorithms of minimization. Namely, conversion from an implication basis to
its graph representation and vice-versa. Because we use lists, adding an edge 
to a given node is constant time. Put another vertex in the graph without edges 
is also constant time for the same reason. Let us consider conversion from 
implications to graph first. We present the theoretical algorithm in 
\ref{alg:conv-imp-graph}. The procedure uses lists of vertices we previously
describe ($L, D, \dots $) instead of theoretical notations such as $E$ for 
edges. Actually, this is just a matter of notations, and whenever
we modify an $L$ list, this can be seen as adding an edge to $E$. We chose this
representation because the algorithm shows creation of the structure (notably 
in memory), and as such, this way of writing demonstrates it better.

\begin{algorithm}
\KwIn{ \\
	\quad $\I$: an implication system \\
	\quad $\Sg$: attribute set}
\KwOut{FD-Graph represention of $\I$ ($G_{\I}$)}

\BlankLine
\BlankLine


\ForEach{$x \in \Sg$}{
	$V = V \cup \{x \}$ \;
}

\BlankLine

\ForEach{$A \imp B \in \I$}{
	\If{$A \notin V$}{
		$V = V \cup \{A \}$ \;
		
		\ForEach{$a \in A$}{
			$L_{A}^{1} = L_{A}^{1} \cup \{a \}$ \;
			$D_{a} = D_{a} \cup \{A \}$ \; 	
		}	
	}

	\ForEach{$b \in B$}{
		$L_{A}^{0} = L_{A}^{0} \cup \{b \}$ \; 
	}
}

\caption{Implications to FD-Graph}
\label{alg:conv-imp-graph}
\end{algorithm}


Provided access to a vertex can be done in $O(1)$, this algorithm runs in linear
time in the size of $\I$. Because access to an element in a list requires linear
time complexity in the size of the list, we used a marking trick to access 
vertices quickly. Access to an element is required to get $D$. Here is the 
idea: we use a temporary array (\lil{std::vector}) of size $|\Sg|$. Whenever we 
add a new attribute to the graph, we add its address to the array at its index
within the attribute set. Because the articles assume reduced form, there is no 
need to test whether a node is already present when adding a new one. Hence, 
the algorithm runs in $O(|\I|)$. In practice however, to widen the application 
field of the algorithm, we added the possibility for $\I$ to have two distinct 
implications with same bodies. Ensuring that a same body is added only once 
requires $O(|B| + |\Sg|)$ time (accessing an element in a list) resulting in an 
$O(|B|^2 + |\I|)$ conversion algorithm.

\vspace{1.2em}

The conversion from graph to implications consists in running over all nodes 
of the graph with non-empty list of full arcs ($O(|B|)$) and adding each vertex
of outgoing full arcs to the conclusion of such nodes ($O(|\Sg|)$). Hence, 
backward conversion is $O(|\I|)$ time consuming.

\vspace{1.2em}

One would be curious about removing a vertex from the graph. Since we use lists
we must run across all nodes to see whether there is outgoing arcs to the node
we wan to remove. Because the closure of a graph has quadratic size with
respect to $\I$, removing a vertex may be quadratic as well. However,
as we have seen in preceding chapter, removing a vertex is highly contextual,
and with sufficient analysis we can achieve better complexity using the 
context of execution.

















